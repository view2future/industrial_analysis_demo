#!/usr/bin/env python3
"""
Monitor and fix report inconsistencies between database and filesystem
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from app_enhanced import app, db, Report
from datetime import datetime
import json

def analyze_reports():
    """Analyze all reports and identify inconsistencies"""
    with app.app_context():
        print("ğŸ” å¼€å§‹åˆ†ææŠ¥å‘ŠçŠ¶æ€...")
        
        # Get all reports
        all_reports = Report.query.all()
        print(f"ğŸ“Š æ•°æ®åº“ä¸­å…±æœ‰ {len(all_reports)} ä¸ªæŠ¥å‘Š")
        
        # Categorize by status
        completed_reports = [r for r in all_reports if r.status == 'completed']
        processing_reports = [r for r in all_reports if r.status == 'processing']
        failed_reports = [r for r in all_reports if r.status == 'failed']
        
        print(f"  âœ… Completed: {len(completed_reports)}")
        print(f"  â³ Processing: {len(processing_reports)}")
        print(f"  âŒ Failed: {len(failed_reports)}")
        print()
        
        # Check filesystem
        output_dir = Path('data/output/llm_reports')
        if output_dir.exists():
            json_files = {f.stem: f for f in output_dir.glob('llm_report_*.json')}
            print(f"ğŸ“ æ–‡ä»¶ç³»ç»Ÿä¸­å…±æœ‰ {len(json_files)} ä¸ªæŠ¥å‘Šæ–‡ä»¶")
        else:
            print("âŒ æŠ¥å‘Šç›®å½•ä¸å­˜åœ¨")
            json_files = {}
        
        print()
        
        # Analyze completed reports
        print("ğŸ” åˆ†æå·²å®Œæˆçš„æŠ¥å‘Š...")
        missing_files = []
        empty_file_paths = []
        invalid_file_paths = []
        valid_completed = []
        
        for report in completed_reports:
            if not report.file_path:
                empty_file_paths.append(report)
                continue
                
            file_path = Path(report.file_path)
            if not file_path.exists():
                missing_files.append(report)
            else:
                # Verify it's a valid JSON file
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        json.load(f)
                    valid_completed.append(report)
                except (json.JSONDecodeError, UnicodeDecodeError):
                    invalid_file_paths.append(report)
        
        print(f"  âœ… æœ‰æ•ˆçš„å·²å®ŒæˆæŠ¥å‘Š: {len(valid_completed)}")
        print(f"  âš ï¸  ç©ºæ–‡ä»¶è·¯å¾„: {len(empty_file_paths)}")
        print(f"  âŒ ç¼ºå¤±æ–‡ä»¶: {len(missing_files)}")
        print(f"  ğŸ”¥ æ— æ•ˆJSONæ–‡ä»¶: {len(invalid_file_paths)}")
        
        if empty_file_paths:
            print("\\nğŸ“‹ ç©ºæ–‡ä»¶è·¯å¾„çš„æŠ¥å‘Š:")
            for report in empty_file_paths[:5]:  # Show first 5
                print(f"  - {report.report_id} (created: {report.created_at})")
            if len(empty_file_paths) > 5:
                print(f"  ... and {len(empty_file_paths) - 5} more")
        
        if missing_files:
            print("\\nğŸ“‹ ç¼ºå¤±æ–‡ä»¶çš„æŠ¥å‘Š:")
            for report in missing_files[:5]:  # Show first 5
                print(f"  - {report.report_id} (expected: {report.file_path})")
            if len(missing_files) > 5:
                print(f"  ... and {len(missing_files) - 5} more")
        
        if invalid_file_paths:
            print("\\nğŸ“‹ æ— æ•ˆJSONæ–‡ä»¶çš„æŠ¥å‘Š:")
            for report in invalid_file_paths[:5]:  # Show first 5
                print(f"  - {report.report_id} (file: {report.file_path})")
            if len(invalid_file_paths) > 5:
                print(f"  ... and {len(invalid_file_paths) - 5} more")
        
        # Analyze processing reports
        print(f"\\nğŸ” åˆ†æå¤„ç†ä¸­çš„æŠ¥å‘Š...")
        stale_processing = []
        recent_processing = []
        
        for report in processing_reports:
            age_hours = (datetime.now() - report.created_at).total_seconds() / 3600
            if age_hours > 2:  # Older than 2 hours
                stale_processing.append((report, age_hours))
            else:
                recent_processing.append((report, age_hours))
        
        print(f"  â° æœ€è¿‘çš„å¤„ç†ä¸­æŠ¥å‘Š (<2å°æ—¶): {len(recent_processing)}")
        print(f"  ğŸ•°ï¸  é™ˆæ—§çš„å¤„ç†ä¸­æŠ¥å‘Š (>2å°æ—¶): {len(stale_processing)}")
        
        if stale_processing:
            print("\\nğŸ“‹ é™ˆæ—§çš„ processing æŠ¥å‘Š (å¯èƒ½éœ€è¦ä¿®å¤):")
            for report, age_hours in stale_processing[:5]:
                print(f"  - {report.report_id} (å¹´é¾„: {age_hours:.1f} å°æ—¶)")
        
        # Find orphaned files (files without database records)
        print(f"\\nğŸ” æ£€æŸ¥å­¤ç«‹æ–‡ä»¶...")
        db_report_ids = {r.report_id for r in all_reports}
        orphaned_files = []
        
        for file_id, file_path in json_files.items():
            if file_id not in db_report_ids:
                orphaned_files.append(file_path)
        
        print(f"  ğŸ—‚ï¸  å­¤ç«‹æ–‡ä»¶ (æ— æ•°æ®åº“è®°å½•): {len(orphaned_files)}")
        if orphaned_files:
            print("ğŸ“‹ å­¤ç«‹æ–‡ä»¶:")
            for file_path in orphaned_files[:5]:
                print(f"  - {file_path.name}")
            if len(orphaned_files) > 5:
                print(f"  ... and {len(orphaned_files) - 5} more")
        
        return {
            'total_reports': len(all_reports),
            'completed': len(completed_reports),
            'processing': len(processing_reports),
            'failed': len(failed_reports),
            'valid_completed': len(valid_completed),
            'empty_file_paths': empty_file_paths,
            'missing_files': missing_files,
            'invalid_file_paths': invalid_file_paths,
            'stale_processing': stale_processing,
            'recent_processing': recent_processing,
            'orphaned_files': orphaned_files,
            'filesystem_files': len(json_files)
        }

def fix_issues(analysis_results):
    """Fix identified issues"""
    with app.app_context():
        print("\\nğŸ”§ å¼€å§‹ä¿®å¤é—®é¢˜...")
        
        fixed_count = 0
        
        # Fix empty file paths in completed reports
        if analysis_results['empty_file_paths']:
            print(f"\\nğŸ› ï¸ ä¿®å¤ç©ºæ–‡ä»¶è·¯å¾„çš„æŠ¥å‘Š ({len(analysis_results['empty_file_paths'])} ä¸ª)...")
            for report in analysis_results['empty_file_paths']:
                expected_path = Path('data/output/llm_reports') / f"{report.report_id}.json"
                if expected_path.exists():
                    report.file_path = str(expected_path)
                    print(f"  âœ… ä¿®å¤: {report.report_id}")
                    fixed_count += 1
                else:
                    print(f"  âš ï¸  æ–‡ä»¶ç¼ºå¤±ï¼Œè®¾ä¸ºfailed: {report.report_id}")
                    report.status = 'failed'
                    report.completed_at = None
                    fixed_count += 1
        
        # Fix stale processing reports
        if analysis_results['stale_processing']:
            print(f"\\nğŸ› ï¸ ä¿®å¤é™ˆæ—§çš„ processing æŠ¥å‘Š ({len(analysis_results['stale_processing'])} ä¸ª)...")
            for report, age_hours in analysis_results['stale_processing']:
                expected_path = Path('data/output/llm_reports') / f"{report.report_id}.json"
                if expected_path.exists():
                    # File exists, mark as completed
                    report.status = 'completed'
                    report.file_path = str(expected_path)
                    print(f"  âœ… å®Œæˆ: {report.report_id} (æ‰¾åˆ°æ–‡ä»¶)")
                else:
                    # File doesn't exist, mark as failed
                    report.status = 'failed'
                    report.completed_at = None
                    print(f"  âŒ å¤±è´¥: {report.report_id} (æ–‡ä»¶ç¼ºå¤±)")
                fixed_count += 1
        
        # Commit all changes
        if fixed_count > 0:
            db.session.commit()
            print(f"\\nâœ… å…±ä¿®å¤äº† {fixed_count} ä¸ªé—®é¢˜")
        else:
            print("\\nâœ… æ²¡æœ‰å‘ç°éœ€è¦ä¿®å¤çš„é—®é¢˜")

def main():
    """Main function"""
    print("ğŸš€ å¯åŠ¨æŠ¥å‘Šç›‘æ§ç³»ç»Ÿ...")
    
    # Analyze reports
    results = analyze_reports()
    
    # Ask if user wants to fix issues
    total_issues = len(results['empty_file_paths']) + len(results['stale_processing'])
    
    if total_issues > 0:
        print(f"\\nâ“ å‘ç° {total_issues} ä¸ªé—®é¢˜ï¼Œæ˜¯å¦ä¿®å¤ï¼Ÿ (yes/no): ", end="")
        try:
            response = input().strip().lower()
            if response == 'yes':
                fix_issues(results)
            else:
                print("\\nâ­ï¸  è·³è¿‡ä¿®å¤")
        except (EOFError, KeyboardInterrupt):
            print("\\nâ­ï¸  è·³è¿‡ä¿®å¤ (æ— è¾“å…¥)")
    else:
        print("\\nâœ… æ²¡æœ‰å‘ç°éœ€è¦ä¿®å¤çš„é—®é¢˜")
    
    print("\\nğŸ‰ æŠ¥å‘Šç›‘æ§å®Œæˆï¼")

if __name__ == '__main__':
    main()