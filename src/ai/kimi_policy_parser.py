#!/usr/bin/env python3
"""
Kimi Policy Parser - Uses Moonshot AI (Kimi) for policy document analysis
"""

import logging
import json
import time
from typing import Dict, Any, List
from openai import OpenAI
import os

logger = logging.getLogger(__name__)


class KimiPolicyParser:
    """Policy parser using Kimi (Moonshot AI) for advanced analysis"""
    
    def __init__(self, config_path: str = 'config.json'):
        """Initialize the Kimi policy parser with API configuration."""
        self.config = self._load_config(config_path)
        
        # Get Kimi API key from config
        api_keys = self.config.get('api_keys', {})
        self.api_key = (
            api_keys.get('kimi')
            or api_keys.get('kimi_api_key')
            or os.environ.get('KIMI_API_KEY')
            or os.environ.get('MOONSHOT_API_KEY')
        )
        
        if not self.api_key:
            raise ValueError("Kimi API key not found in config or environment variables")
        
        # Initialize the OpenAI client with Kimi endpoint
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.moonshot.cn/v1"
        )
        
        # Use a high-context model for better policy understanding
        self.model = "moonshot-v1-128k"
        self.temperature = 0.3  # Lower temperature for more consistent analysis
        self.max_tokens = 4000  # Sufficient for detailed policy analysis
        
        logger.info("âœ… Kimi Policy Parser initialized successfully")
    
    def _load_config(self, config_path: str) -> Dict:
        """Load configuration from JSON file."""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Error loading config: {e}")
            return {}
    
    def parse_policy_document(self, document_text: str) -> Dict[str, Any]:
        """
        Parse a policy document using Kimi AI for comprehensive analysis.
        
        Args:
            document_text: The full text of the policy document
            
        Returns:
            Dict containing structured policy analysis results
        """
        try:
            logger.info("ğŸš€ Starting Kimi policy analysis...")
            start_time = time.time()
            
            # Prepare the prompt for policy analysis
            prompt = self._create_policy_analysis_prompt(document_text)
            
            # Call Kimi API
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """You are an expert policy analyst. Analyze the given policy document and extract key information in JSON format. Be precise, comprehensive, and structure the information logically. Focus on identifying specific amounts, dates, eligibility criteria, and requirements."""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                response_format={"type": "json_object"}  # Request JSON output
            )
            
            response_text = completion.choices[0].message.content
            logger.info(f"âœ… Kimi API call completed in {time.time() - start_time:.2f}s")
            
            # Parse the JSON response
            try:
                result = json.loads(response_text)
                logger.info("âœ… Policy analysis completed successfully")
                return self._validate_and_format_result(result, document_text)
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse JSON response: {e}")
                logger.error(f"Raw response: {response_text[:500]}...")
                # Fallback: return basic structure
                return self._create_fallback_result(document_text)
                
        except Exception as e:
            logger.error(f"âŒ Kimi policy analysis failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return self._create_fallback_result(document_text, error=str(e))
    
    def _create_policy_analysis_prompt(self, document_text: str) -> str:
        """Create the prompt for policy analysis using the local prompt file."""
        # Read the local prompt template
        try:
            with open('policy_analysis_prompt.md', 'r', encoding='utf-8') as f:
                prompt_template = f.read()
        except FileNotFoundError:
            # Try different possible filenames
            try:
                with open('policy_analysis_prompt.txt', 'r', encoding='utf-8') as f:
                    prompt_template = f.read()
            except FileNotFoundError:
                logger.warning("Policy analysis prompt file not found, using fallback prompt")
                # Fallback prompt if no file is available
                prompt_template = """# æ”¿ç­–æ–‡ä»¶æ·±åº¦åˆ†ææŠ¥å‘Š

## 1. æ”¿ç­–æ‘˜è¦ (Policy Summary)

* **æ ¸å¿ƒå†…å®¹æç‚¼**ï¼šè¯·ä»ä»¥ä¸‹æ”¿ç­–æ–‡æ¡£ä¸­ç²¾ç‚¼å‡ºæ ¸å¿ƒæ”¿ç­–å†…å®¹ï¼ŒåŒ…æ‹¬æ”¿ç­–ç›®æ ‡ã€ä¸»è¦æªæ–½ã€é€‚ç”¨å¯¹è±¡ã€å®æ–½æœŸé™ç­‰å…³é”®ä¿¡æ¯ã€‚
* **å…³é”®è¦ç‚¹æ¦‚è¿°**ï¼šç”¨2-3å¥è¯æ¦‚æ‹¬æ”¿ç­–çš„æ ¸å¿ƒè¦ç‚¹å’Œå½±å“ã€‚

## 2. æ”¿ç­–è¦ç‚¹åˆ†ç±» (Policy Key Points)

è¯·å°†æ”¿ç­–å†…å®¹æŒ‰ä»¥ä¸‹ç±»åˆ«è¿›è¡Œåˆ†é—¨åˆ«ç±»åœ°ç½—åˆ—ï¼š

### èµ„é‡‘æ”¯æŒç±»
* è¯¦ç»†åˆ—å‡ºæ”¿ç­–ä¸­æåŠçš„èµ„é‡‘è¡¥è´´ã€å¥–åŠ±ã€ä¸“é¡¹èµ„é‡‘ç­‰é‡åŒ–æŒ‡æ ‡
* åŒ…æ‹¬é‡‘é¢èŒƒå›´ã€ç”³è¯·æ¡ä»¶ã€æ”¯æŒæ¯”ä¾‹ç­‰å…·ä½“æ•°æ®

### ç¨æ”¶ä¼˜æƒ ç±»
* æ˜ç¡®åˆ—å‡ºå„é¡¹ç¨æ”¶å‡å…ã€ä¼˜æƒ æ”¿ç­–
* æ³¨æ˜é€‚ç”¨ç¨ç‡ã€å‡å…å¹…åº¦ã€æ‰§è¡ŒæœŸé™ç­‰

### äººæ‰æ”¯æŒç±»
* äººæ‰å¼•è¿›ã€åŸ¹è®­ã€æ¿€åŠ±ç­‰ç›¸å…³æ”¿ç­–æ¡æ¬¾
* åŒ…æ‹¬è¡¥è´´é‡‘é¢ã€ä¼˜æƒ æ”¿ç­–ã€æœåŠ¡ä¿éšœç­‰å†…å®¹

### åœŸåœ°æ”¿ç­–ç±»
* åœŸåœ°ä½¿ç”¨ã€ç§Ÿé‡‘å‡å…ã€äº§ä¸šå›­åŒºç­‰ç›¸å…³æ”¿ç­–
* æ³¨æ˜é¢ç§¯ã€ä»·æ ¼ã€æœŸé™ç­‰å…·ä½“é‡åŒ–æŒ‡æ ‡

### é‡‘èæ”¯æŒç±»
* è´·æ¬¾ã€èèµ„ã€æ‹…ä¿ç­‰é‡‘èæ”¯æŒæ”¿ç­–
* åŒ…æ‹¬åˆ©ç‡ã€é¢åº¦ã€æœŸé™ã€è´´æ¯æ¯”ä¾‹ç­‰æ•°æ®

### å…¶ä»–æ”¯æŒç±»
* å…¶ä»–å½¢å¼çš„æ”¿ç­–æ”¯æŒæªæ–½
* å¦‚å®¡æ‰¹ç»¿è‰²é€šé“ã€ç®€åŒ–æµç¨‹ç­‰

### å¹´åº¦ç›®æ ‡ä¸é‡åŒ–æŒ‡æ ‡
* æ”¿ç­–ä¸­æ˜ç¡®çš„å„é¡¹ç›®æ ‡å’Œé‡åŒ–æŒ‡æ ‡
* åŒ…æ‹¬æ—¶é—´èŠ‚ç‚¹ã€å®Œæˆæ ‡å‡†ã€é¢„æœŸæ•ˆæœç­‰

## 3. äº§ä¸šé“¾åˆ†æ (Industry Chain Analysis)

è¯·æ ¹æ®æ”¿ç­–æ–‡ä»¶å†…å®¹ï¼Œè¯†åˆ«å¹¶åˆ†æç›¸å…³äº§ä¸šçš„ä¸Šä¸­ä¸‹æ¸¸ç»“æ„ï¼š

### ä¸Šæ¸¸äº§ä¸š (Upstream Industries)
* æ”¿ç­–æ¶‰åŠçš„åŸææ–™ã€åŸºç¡€è®¾å¤‡ã€æ ¸å¿ƒé›¶éƒ¨ä»¶ç­‰ç›¸å…³äº§ä¸š
* æ”¿ç­–å¯¹ä¸Šæ¸¸äº§ä¸šçš„å½±å“å’Œæ”¯æŒæªæ–½

### ä¸­æ¸¸äº§ä¸š (Midstream Industries)
* æ”¿ç­–æ¶‰åŠçš„æ ¸å¿ƒç”Ÿäº§ã€åˆ¶é€ ã€é›†æˆç­‰ç›¸å…³äº§ä¸š
* æ”¿ç­–å¯¹ä¸­æ¸¸äº§ä¸šçš„ä¸»è¦æ‰¶æŒæªæ–½

### ä¸‹æ¸¸äº§ä¸š (Downstream Industries)
* æ”¿ç­–æ¶‰åŠçš„åº”ç”¨å¸‚åœºã€æœåŠ¡ã€é”€å”®æ¸ é“ç­‰ç›¸å…³äº§ä¸š
* æ”¿ç­–å¯¹ä¸‹æ¸¸äº§ä¸šçš„æ¨åŠ¨ä½œç”¨

### äº§ä¸šé“¾ååŒ
* ä¸Šä¸­ä¸‹æ¸¸äº§ä¸šé“¾ååŒå‘å±•çš„æ”¿ç­–æªæ–½
* äº§ä¸šé“¾è¡¥é“¾å¼ºé“¾çš„å…·ä½“ä¸¾æª

## 4. æ³¨æ„äº‹é¡¹

* **å‡†ç¡®æå–**ï¼šä¸¥æ ¼æŒ‰ç…§æ”¿ç­–åŸæ–‡å†…å®¹è¿›è¡Œåˆ†æï¼Œä¸å¾—ç¼–é€ æˆ–æ¨æµ‹
* **é‡åŒ–æŒ‡æ ‡ä¼˜å…ˆ**ï¼šä¼˜å…ˆæå–å’Œå±•ç¤ºæ”¿ç­–ä¸­çš„å…·ä½“æ•°æ®ã€é‡‘é¢ã€æ¯”ä¾‹ç­‰é‡åŒ–æŒ‡æ ‡
* **æ—¶é—´èŠ‚ç‚¹æ˜ç¡®**ï¼šæ˜ç¡®æ ‡æ³¨æ”¿ç­–å®æ–½ã€ç”³æŠ¥ã€æˆªæ­¢ç­‰ç›¸å…³æ—¶é—´èŠ‚ç‚¹
* **ç»“æ„æ¸…æ™°**ï¼šæŒ‰ç…§ä¸Šè¿°åˆ†ç±»æ¸…æ™°æœ‰åºåœ°å±•ç¤ºæ”¿ç­–å†…å®¹
* **å»é™¤é€‚ç”¨æ€§è¯„åˆ†**ï¼šä¸åŒ…å«ä»»ä½•å…³äºé€‚ç”¨æ€§è¯„åˆ†çš„å†…å®¹

ç°åœ¨è¯·å¼€å§‹åˆ†æä»¥ä¸‹æ”¿ç­–æ–‡æ¡£ï¼š"""

        # Limit document length to prevent exceeding token limits
        max_length = 20000  # Keep prompt under reasonable length
        truncated_text = document_text[:max_length] if len(document_text) > max_length else document_text

        # Replace the placeholder in the prompt
        return prompt_template.replace("ç°åœ¨è¯·å¼€å§‹åˆ†ææä¾›çš„æ”¿ç­–æ–‡æ¡£ã€‚",
                                      f"ç°åœ¨è¯·å¼€å§‹åˆ†æä»¥ä¸‹æ”¿ç­–æ–‡æ¡£ï¼š\n\n{truncated_text}")
    
    def _validate_and_format_result(self, result: Dict[str, Any], original_text: str) -> Dict[str, Any]:
        """Validate and format the result to ensure complete structure."""
        # Ensure required top-level keys exist
        required_keys = [
            'metadata', 'document_structure', 'entities', 'provisions', 
            'requirements', 'quantitative_data', 'timeline', 
            'relationships', 'key_points', 'analysis', 'full_text'
        ]
        
        for key in required_keys:
            if key not in result:
                if key == 'metadata':
                    result[key] = {
                        'title': 'æ”¿ç­–æ ‡é¢˜',
                        'issuing_authority': 'å‘å¸ƒæœºæ„',
                        'publication_date': '',
                        'applicable_regions': [],
                        'key_industries': []
                    }
                elif key == 'document_structure':
                    result[key] = []
                elif key == 'entities':
                    result[key] = {
                        'organizations': [],
                        'key_personnel': [],
                        'geographical_entities': []
                    }
                elif key == 'provisions':
                    result[key] = []
                elif key == 'requirements':
                    result[key] = []
                elif key == 'quantitative_data':
                    result[key] = {
                        'amounts': [], 'thresholds': [], 
                        'ratios': [], 'time_periods': []
                    }
                elif key == 'timeline':
                    result[key] = []
                elif key == 'relationships':
                    result[key] = []
                elif key == 'key_points':
                    result[key] = ['æ”¿ç­–è¦ç‚¹']
                elif key == 'analysis':
                    result[key] = {
                        'industry_relevance': {
                            'value_chain': {
                                'upstream': [], 'midstream': [], 'downstream': []
                            },
                            'related_industries': []
                        },
                        'policy_strength': {
                            'funding_level': 'Medium',
                            'measure_diversity': 0,
                            'support_comprehensiveness': 'Partial'
                        },
                        'timeliness_score': 70,
                        'regional_match_score': 75
                    }
                elif key == 'full_text':
                    result[key] = original_text
        
        # Set the original text as full_text if not provided or empty
        if not result.get('full_text'):
            result['full_text'] = original_text
            
        return result
    
    def _create_fallback_result(self, document_text: str, error: str = "") -> Dict[str, Any]:
        """Create a fallback result when Kimi analysis fails."""
        logger.warning(f"Falling back to basic analysis due to error: {error}")
        
        return {
            'metadata': {
                'title': 'Kimiè§£æå¤±è´¥ - ä½¿ç”¨æœ¬åœ°è§£æ',
                'issuing_authority': 'æœªçŸ¥',
                'publication_date': '',
                'applicable_regions': [],
                'key_industries': []
            },
            'document_structure': [{'section': 'å…¨æ–‡', 'content': 'Kimiè§£æå¤±è´¥ï¼Œå†…å®¹æ˜¾ç¤º'}],
            'entities': {
                'organizations': [],
                'key_personnel': [],
                'geographical_entities': []
            },
            'provisions': [],
            'requirements': [],
            'quantitative_data': {
                'amounts': [], 'thresholds': [], 
                'ratios': [], 'time_periods': []
            },
            'timeline': [],
            'relationships': [],
            'key_points': [document_text[:500] + '...' if len(document_text) > 500 else document_text],
            'analysis': {
                'industry_relevance': {
                    'value_chain': {
                        'upstream': [], 'midstream': [], 'downstream': []
                    },
                    'related_industries': []
                },
                'policy_strength': {
                    'funding_level': 'Unknown',
                    'measure_diversity': 0,
                    'support_comprehensiveness': 'Unknown'
                },
                'timeliness_score': 0,
                'regional_match_score': 0
            },
            'full_text': document_text
        }


if __name__ == "__main__":
    # Test the Kimi policy parser
    logging.basicConfig(level=logging.INFO)
    
    try:
        parser = KimiPolicyParser()
        test_document = """
        å…³äºæ”¯æŒäººå·¥æ™ºèƒ½äº§ä¸šå‘å±•çš„è‹¥å¹²æ”¿ç­–
        
        ä¸ºè´¯å½»è½å®å›½å®¶å…³äºå‘å±•äººå·¥æ™ºèƒ½çš„æˆ˜ç•¥éƒ¨ç½²ï¼Œæ”¯æŒæˆ‘å¸‚äººå·¥æ™ºèƒ½äº§ä¸šå‘å±•ï¼Œ
        ç‰¹åˆ¶å®šæœ¬æ”¿ç­–ã€‚
        
        ä¸€ã€æ€»ä½“ç›®æ ‡
        åˆ°2025å¹´ï¼Œå…¨å¸‚äººå·¥æ™ºèƒ½æ ¸å¿ƒäº§ä¸šè§„æ¨¡è¾¾åˆ°500äº¿å…ƒï¼ŒåŸ¹è‚²100å®¶ä»¥ä¸Šäººå·¥æ™ºèƒ½ä¼ä¸šã€‚
        
        äºŒã€æ”¯æŒæªæ–½
        1. èµ„é‡‘æ”¯æŒï¼šè®¾ç«‹äººå·¥æ™ºèƒ½äº§ä¸šå‘å±•ä¸“é¡¹èµ„é‡‘ï¼Œæ¯å¹´å®‰æ’ä¸å°‘äº10äº¿å…ƒã€‚
        2. ç¨æ”¶ä¼˜æƒ ï¼šå¯¹é«˜æ–°æŠ€æœ¯ä¼ä¸šå‡æŒ‰15%ç¨ç‡å¾æ”¶ä¼ä¸šæ‰€å¾—ç¨ã€‚
        3. äººæ‰å¼•è¿›ï¼šå¯¹å¼•è¿›çš„é«˜å±‚æ¬¡äººæ‰ç»™äºˆæœ€é«˜200ä¸‡å…ƒå®‰å®¶è¡¥è´´ã€‚
        
        ä¸‰ã€ç”³æŠ¥æ—¶é—´
        è‡ª2024å¹´3æœˆ1æ—¥èµ·è‡³2024å¹´6æœˆ30æ—¥æ­¢ã€‚
        """
        
        result = parser.parse_policy_document(test_document)
        print(f"âœ… Kimi policy parsing completed!")
        print(f"Title: {result['metadata']['title']}")
        print(f"Key industries: {result['metadata']['key_industries']}")
        print(f"Quantitative data amounts: {len(result['quantitative_data']['amounts'])}")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()